#!/usr/bin/env python3
"""
OsmanlÄ±ca Belge Ä°ndirici ve HazÄ±rlayÄ±cÄ±

Bu script, aÃ§Ä±k kaynak OsmanlÄ±ca belgelerini indirir ve eÄŸitim iÃ§in hazÄ±rlar.
"""

import os
import requests
from pathlib import Path
import json
from typing import List, Dict
import time

# AÃ§Ä±k kaynak OsmanlÄ±ca belge kaynaklarÄ±
OPEN_SOURCES = {
    "archive_org": {
        "name": "Internet Archive - Ottoman Turkish Books",
        "collections": [
            "ottoman-turkish",
            "osmanliturkcekitaplar",
            "turkishmanuscripts",
        ],
        "api_base": "https://archive.org/services/search/v1/scrape"
    },
    "wikisource": {
        "name": "Wikisource - Ottoman Turkish",
        "url": "https://tr.wikisource.org/wiki/Kategori:OsmanlÄ±ca_metinler",
        "api": "https://tr.wikisource.org/w/api.php"
    },
    "hathitrust": {
        "name": "HathiTrust Digital Library",
        "search": "https://babel.hathitrust.org/cgi/ls?a=srchls&q1=ottoman+turkish&lmt=ft",
        "note": "Public domain books only"
    }
}

class OttomanDocumentCollector:
    """AÃ§Ä±k kaynak OsmanlÄ±ca belgelerini toplayan sÄ±nÄ±f"""
    
    def __init__(self, output_dir="training-data/collected"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.images_dir = self.output_dir / "images"
        self.metadata_dir = self.output_dir / "metadata"
        
        self.images_dir.mkdir(exist_ok=True)
        self.metadata_dir.mkdir(exist_ok=True)
    
    def search_archive_org(self, query="ottoman turkish", max_results=50):
        """
        Archive.org'da OsmanlÄ±ca belgeler ara
        
        Args:
            query: Arama sorgusu
            max_results: Maksimum sonuÃ§ sayÄ±sÄ±
        """
        print(f"\nğŸ” Archive.org'da aranÄ±yor: '{query}'")
        
        # Archive.org Advanced Search API
        params = {
            "q": f"{query} AND mediatype:texts",
            "fl[]": ["identifier", "title", "creator", "year", "language"],
            "rows": max_results,
            "page": 1
        }
        
        try:
            response = requests.get(OPEN_SOURCES["archive_org"]["api_base"], params=params)
            if response.status_code == 200:
                data = response.json()
                items = data.get("items", [])
                
                print(f"âœ… {len(items)} belge bulundu")
                
                # SonuÃ§larÄ± kaydet
                results_file = self.metadata_dir / "archive_org_results.json"
                with open(results_file, 'w', encoding='utf-8') as f:
                    json.dump(items, f, indent=2, ensure_ascii=False)
                
                return items
            else:
                print(f"âŒ Hata: {response.status_code}")
                return []
        except Exception as e:
            print(f"âŒ Hata: {e}")
            return []
    
    def get_recommended_sources(self):
        """
        Elle seÃ§ilmiÅŸ, kaliteli aÃ§Ä±k kaynak OsmanlÄ±ca kaynaklar
        """
        recommendations = [
            {
                "source": "Archive.org",
                "id": "kitbuttevhid00sade",
                "title": "Kitab-Ã¼t Tevhid",
                "url": "https://archive.org/details/kitbuttevhid00sade",
                "pages": 200,
                "quality": "high",
                "license": "Public Domain",
                "format": "DjVu, PDF",
                "notes": "19. yÃ¼zyÄ±l OsmanlÄ±ca matbu eser, net baskÄ±"
            },
            {
                "source": "Archive.org",
                "id": "mevlidiveysihan00gazi",
                "title": "Mevlidi Veysi Han",
                "url": "https://archive.org/details/mevlidiveysihan00gazi",
                "pages": 150,
                "quality": "high",
                "license": "Public Domain"
            },
            {
                "source": "Archive.org",
                "id": "gulistn00saadi",
                "title": "GÃ¼listan (OsmanlÄ±ca tercÃ¼me)",
                "url": "https://archive.org/details/gulistn00saadi",
                "pages": 300,
                "quality": "high",
                "license": "Public Domain"
            },
            {
                "source": "Wikisource",
                "title": "Tanzimat FermanÄ±",
                "url": "https://tr.wikisource.org/wiki/Tanzimat_FermanÄ±",
                "pages": 5,
                "quality": "high",
                "transcription": "Available",
                "license": "CC0"
            }
        ]
        
        return recommendations
    
    def download_archive_org_item(self, identifier, max_pages=None):
        """
        Archive.org'dan belge indir
        
        Args:
            identifier: Archive.org item ID
            max_pages: Maksimum sayfa sayÄ±sÄ± (None = tÃ¼mÃ¼)
        """
        print(f"\nğŸ“¥ Ä°ndiriliyor: {identifier}")
        
        # Metadata al
        metadata_url = f"https://archive.org/metadata/{identifier}"
        try:
            response = requests.get(metadata_url)
            if response.status_code != 200:
                print(f"âŒ Metadata alÄ±namadÄ±: {response.status_code}")
                return False
            
            metadata = response.json()
            title = metadata.get('metadata', {}).get('title', identifier)
            
            print(f"ğŸ“– BaÅŸlÄ±k: {title}")
            
            # PDF veya DjVu dosyasÄ±nÄ± bul
            files = metadata.get('files', [])
            pdf_file = None
            djvu_file = None
            
            for file in files:
                name = file.get('name', '')
                if name.endswith('.pdf'):
                    pdf_file = name
                elif name.endswith('.djvu'):
                    djvu_file = name
            
            download_file = pdf_file or djvu_file
            
            if not download_file:
                print("âŒ PDF veya DjVu dosyasÄ± bulunamadÄ±")
                return False
            
            # Ä°ndir
            download_url = f"https://archive.org/download/{identifier}/{download_file}"
            print(f"â¬‡ï¸  Ä°ndiriliyor: {download_url}")
            
            # Dosya adÄ±
            safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).strip()
            output_file = self.output_dir / f"{identifier}_{safe_title}.{download_file.split('.')[-1]}"
            
            # Ä°ndirme (bÃ¼yÃ¼k dosyalar iÃ§in streaming)
            with requests.get(download_url, stream=True) as r:
                r.raise_for_status()
                total_size = int(r.headers.get('content-length', 0))
                
                with open(output_file, 'wb') as f:
                    downloaded = 0
                    for chunk in r.iter_content(chunk_size=8192):
                        f.write(chunk)
                        downloaded += len(chunk)
                        if total_size:
                            percent = (downloaded / total_size) * 100
                            print(f"\râ³ Ä°lerleme: {percent:.1f}%", end='')
            
            print(f"\nâœ… Ä°ndirildi: {output_file}")
            
            # Metadata kaydet
            metadata_file = self.metadata_dir / f"{identifier}_metadata.json"
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            return output_file
            
        except Exception as e:
            print(f"âŒ Hata: {e}")
            return False
    
    def generate_collection_report(self):
        """
        Toplanan belgeler hakkÄ±nda rapor oluÅŸtur
        """
        report_file = self.output_dir / "COLLECTION_REPORT.md"
        
        # DosyalarÄ± tara
        pdf_files = list(self.output_dir.glob("*.pdf"))
        djvu_files = list(self.output_dir.glob("*.djvu"))
        metadata_files = list(self.metadata_dir.glob("*_metadata.json"))
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# Toplanan OsmanlÄ±ca Belgeler Raporu\n\n")
            f.write(f"**Tarih**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## Ã–zet\n\n")
            f.write(f"- PDF DosyalarÄ±: {len(pdf_files)}\n")
            f.write(f"- DjVu DosyalarÄ±: {len(djvu_files)}\n")
            f.write(f"- Toplam: {len(pdf_files) + len(djvu_files)} belge\n\n")
            
            f.write("## Ä°ndirilen Belgeler\n\n")
            
            for pdf in pdf_files:
                f.write(f"- ğŸ“„ {pdf.name}\n")
            
            for djvu in djvu_files:
                f.write(f"- ğŸ“„ {djvu.name}\n")
            
            f.write("\n## Sonraki AdÄ±mlar\n\n")
            f.write("1. PDF/DjVu dosyalarÄ±nÄ± PNG gÃ¶rÃ¼ntÃ¼lere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n\n")
            f.write("2. Ground truth transkripsiyon oluÅŸturun\n")
            f.write("3. training-data/images/ ve training-data/ground-truth/ dizinlerine ekleyin\n")
            f.write("4. Model eÄŸitimini baÅŸlatÄ±n\n")
        
        print(f"\nğŸ“Š Rapor oluÅŸturuldu: {report_file}")


def main():
    """Ana script"""
    import argparse
    
    parser = argparse.ArgumentParser(description='OsmanlÄ±ca belge toplayÄ±cÄ±')
    parser.add_argument('--action', choices=['search', 'download', 'recommend'], 
                       default='recommend',
                       help='YapÄ±lacak iÅŸlem')
    parser.add_argument('--query', default='ottoman turkish',
                       help='Arama sorgusu')
    parser.add_argument('--identifier', 
                       help='Archive.org belge ID')
    
    args = parser.parse_args()
    
    collector = OttomanDocumentCollector()
    
    if args.action == 'search':
        results = collector.search_archive_org(args.query)
        print(f"\nâœ… {len(results)} sonuÃ§ bulundu")
        print("ğŸ“ SonuÃ§lar: training-data/collected/metadata/archive_org_results.json")
    
    elif args.action == 'download':
        if not args.identifier:
            print("âŒ --identifier parametresi gerekli")
            return
        
        collector.download_archive_org_item(args.identifier)
    
    elif args.action == 'recommend':
        recommendations = collector.get_recommended_sources()
        
        print("\n" + "="*60)
        print("  Ã–NERÄ°LEN KALÄ°TELÄ° OSMANICA KAYNAKLAR")
        print("="*60 + "\n")
        
        for i, rec in enumerate(recommendations, 1):
            print(f"{i}. {rec['title']}")
            print(f"   ğŸ“ Kaynak: {rec['source']}")
            print(f"   ğŸ”— URL: {rec['url']}")
            print(f"   ğŸ“„ Sayfa: {rec['pages']}")
            print(f"   â­ Kalite: {rec['quality']}")
            print(f"   ğŸ“œ Lisans: {rec['license']}")
            if 'id' in rec:
                print(f"   ğŸ†” ID: {rec['id']}")
            print()
        
        print("Ä°ndirmek iÃ§in:")
        print("python scripts/collect_documents.py --action download --identifier <ID>")
        
        collector.generate_collection_report()


if __name__ == '__main__':
    main()
