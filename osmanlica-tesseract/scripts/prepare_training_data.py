#!/usr/bin/env python3
"""
PDF/DjVu'dan EÄŸitim Verisi HazÄ±rlayÄ±cÄ±

Ä°ndirilen belgeleri eÄŸitim iÃ§in hazÄ±rlar.
"""

import os
import sys
from pathlib import Path
from PIL import Image
import subprocess
import json

class TrainingDataPreparer:
    """Belgeleri eÄŸitim verisi formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r"""
    
    def __init__(self, source_dir="training-data/collected", 
                 output_images="training-data/images",
                 output_gt="training-data/ground-truth"):
        self.source_dir = Path(source_dir)
        self.images_dir = Path(output_images)
        self.gt_dir = Path(output_gt)
        
        self.images_dir.mkdir(parents=True, exist_ok=True)
        self.gt_dir.mkdir(parents=True, exist_ok=True)
    
    def pdf_to_images(self, pdf_file, dpi=300, max_pages=None):
        """
        PDF'i gÃ¶rÃ¼ntÃ¼lere dÃ¶nÃ¼ÅŸtÃ¼r
        
        Args:
            pdf_file: PDF dosya yolu
            dpi: Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k
            max_pages: Maksimum sayfa (None = tÃ¼mÃ¼)
        """
        pdf_path = Path(pdf_file)
        if not pdf_path.exists():
            print(f"âŒ Dosya bulunamadÄ±: {pdf_file}")
            return []
        
        print(f"\nğŸ“„ PDF iÅŸleniyor: {pdf_path.name}")
        
        # Ã‡Ä±ktÄ± dizini
        doc_name = pdf_path.stem
        
        try:
            # pdftoppm ile PDF'i PNG'ye Ã§evir (poppler-utils gerekli)
            cmd = [
                'pdftoppm',
                '-png',
                '-r', str(dpi),
                str(pdf_path),
                str(self.images_dir / doc_name)
            ]
            
            if max_pages:
                cmd.extend(['-l', str(max_pages)])
            
            print(f"âš™ï¸  Komut: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                # OluÅŸturulan dosyalarÄ± bul
                created_files = list(self.images_dir.glob(f"{doc_name}-*.png"))
                print(f"âœ… {len(created_files)} sayfa dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼")
                return created_files
            else:
                print(f"âŒ Hata: {result.stderr}")
                return []
                
        except FileNotFoundError:
            print("âŒ pdftoppm bulunamadÄ±. Kurulum:")
            print("   Ubuntu/Debian: sudo apt-get install poppler-utils")
            print("   macOS: brew install poppler")
            return []
        except Exception as e:
            print(f"âŒ Hata: {e}")
            return []
    
    def create_placeholder_groundtruth(self, image_files):
        """
        GÃ¶rÃ¼ntÃ¼ler iÃ§in placeholder ground truth dosyalarÄ± oluÅŸtur
        
        Args:
            image_files: GÃ¶rÃ¼ntÃ¼ dosyalarÄ± listesi
        """
        print(f"\nğŸ“ Ground truth placeholder'larÄ± oluÅŸturuluyor...")
        
        for img_file in image_files:
            # Ground truth dosya adÄ±
            gt_file = self.gt_dir / f"{img_file.stem}.gt.txt"
            
            if not gt_file.exists():
                with open(gt_file, 'w', encoding='utf-8') as f:
                    f.write("# TODO: Bu sayfanÄ±n transkripsiyon ekleyin\n")
                    f.write("# OsmanlÄ±ca metin buraya yazÄ±lacak\n")
                    f.write("#\n")
                    f.write("# AraÃ§lar:\n")
                    f.write("# - Transkribus: https://readcoop.eu/transkribus/\n")
                    f.write("# - Manuel transkripsiyon\n")
                    f.write("#\n")
                    f.write("# GÃ¶rÃ¼ntÃ¼: {}\n".format(img_file.name))
        
        print(f"âœ… {len(image_files)} ground truth dosyasÄ± oluÅŸturuldu")
        print(f"ğŸ“ Konum: {self.gt_dir}")
        print("\nâš ï¸  DÄ°KKAT: Ground truth dosyalarÄ±nÄ± manuel olarak doldurmanÄ±z gerekiyor!")
    
    def optimize_images(self, image_dir=None):
        """
        GÃ¶rÃ¼ntÃ¼leri OCR iÃ§in optimize et
        
        Args:
            image_dir: GÃ¶rÃ¼ntÃ¼ dizini (None = varsayÄ±lan)
        """
        if image_dir is None:
            image_dir = self.images_dir
        
        print(f"\nğŸ”§ GÃ¶rÃ¼ntÃ¼ler optimize ediliyor...")
        
        from scripts.preprocess import preprocess_image
        
        optimized_dir = image_dir.parent / f"{image_dir.name}_optimized"
        optimized_dir.mkdir(exist_ok=True)
        
        image_files = list(image_dir.glob("*.png"))
        
        for img_file in image_files:
            output_file = optimized_dir / img_file.name
            
            try:
                preprocess_image(
                    str(img_file),
                    str(output_file),
                    denoise=True,
                    deskew=True,
                    binarize=True,
                    enhance_contrast=True
                )
                print(f"âœ… {img_file.name}")
            except Exception as e:
                print(f"âŒ {img_file.name}: {e}")
        
        print(f"\nâœ… Optimize edilmiÅŸ gÃ¶rÃ¼ntÃ¼ler: {optimized_dir}")


def create_dataset_readme(output_dir):
    """
    Veri seti iÃ§in README oluÅŸtur
    """
    readme_file = Path(output_dir) / "DATASET_README.md"
    
    with open(readme_file, 'w', encoding='utf-8') as f:
        f.write("# OsmanlÄ±ca EÄŸitim Veri Seti\n\n")
        f.write("Bu veri seti aÃ§Ä±k kaynak OsmanlÄ±ca belgelerinden oluÅŸturulmuÅŸtur.\n\n")
        
        f.write("## Kaynak\n\n")
        f.write("- Archive.org (Public Domain)\n")
        f.write("- Wikisource (CC0 / Public Domain)\n")
        f.write("- DiÄŸer aÃ§Ä±k kaynak koleksiyonlar\n\n")
        
        f.write("## Lisans\n\n")
        f.write("Bu belgeler kamu malÄ±dÄ±r (Public Domain) veya aÃ§Ä±k lisanslÄ±dÄ±r.\n")
        f.write("KullanÄ±m, daÄŸÄ±tÄ±m ve deÄŸiÅŸtirme serbesttir.\n\n")
        
        f.write("## KullanÄ±m\n\n")
        f.write("```bash\n")
        f.write("# Model eÄŸitimi\n")
        f.write("python scripts/train_tesseract.py \\\n")
        f.write("    --action finetune \\\n")
        f.write("    --base-model ara \\\n")
        f.write("    --iterations 10000\n")
        f.write("```\n\n")
        
        f.write("## Ground Truth\n\n")
        f.write("âš ï¸ **Ã–NEMLÄ°**: Ground truth dosyalarÄ± manuel transkripsiyon gerektirir!\n\n")
        f.write("Her gÃ¶rÃ¼ntÃ¼ iÃ§in `.gt.txt` dosyasÄ±nÄ± dÃ¼zenleyin:\n")
        f.write("1. GÃ¶rÃ¼ntÃ¼yÃ¼ aÃ§Ä±n\n")
        f.write("2. Metni doÄŸru bir ÅŸekilde transkribe edin\n")
        f.write("3. UTF-8 formatÄ±nda kaydedin\n\n")
        
        f.write("## Ä°statistikler\n\n")
        
        # Ä°statistikleri hesapla
        images_dir = Path(output_dir) / "../images"
        if images_dir.exists():
            image_files = list(images_dir.glob("*.png"))
            f.write(f"- GÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±: {len(image_files)}\n")
        
        f.write("\n## KatkÄ±da Bulunma\n\n")
        f.write("Ground truth transkripsiyon katkÄ±larÄ±nÄ±zÄ± bekliyoruz!\n")
    
    print(f"\nğŸ“„ README oluÅŸturuldu: {readme_file}")


def main():
    """Ana iÅŸlev"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Belgeleri eÄŸitim verisi formatÄ±na hazÄ±rla')
    parser.add_argument('--pdf', help='Ä°ÅŸlenecek PDF dosyasÄ±')
    parser.add_argument('--dpi', type=int, default=300, help='Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k (DPI)')
    parser.add_argument('--max-pages', type=int, help='Maksimum sayfa sayÄ±sÄ±')
    parser.add_argument('--optimize', action='store_true', help='GÃ¶rÃ¼ntÃ¼leri optimize et')
    
    args = parser.parse_args()
    
    preparer = TrainingDataPreparer()
    
    if args.pdf:
        # PDF'i iÅŸle
        image_files = preparer.pdf_to_images(args.pdf, args.dpi, args.max_pages)
        
        if image_files:
            # Ground truth placeholder'larÄ± oluÅŸtur
            preparer.create_placeholder_groundtruth(image_files)
            
            # Optimize et
            if args.optimize:
                preparer.optimize_images()
            
            # README oluÅŸtur
            create_dataset_readme("training-data")
            
            print("\n" + "="*60)
            print("  BAÅARILI!")
            print("="*60)
            print(f"\nâœ… {len(image_files)} sayfa hazÄ±rlandÄ±")
            print(f"ğŸ“ GÃ¶rÃ¼ntÃ¼ler: training-data/images/")
            print(f"ğŸ“ Ground truth: training-data/ground-truth/")
            print("\nâš ï¸  SONRAKÄ° ADIM: Ground truth dosyalarÄ±nÄ± manuel olarak doldurun!")
            print("   Her .gt.txt dosyasÄ±nÄ± aÃ§Ä±p OsmanlÄ±ca metni transkribe edin.")
    else:
        print("KullanÄ±m: python scripts/prepare_training_data.py --pdf <dosya.pdf>")
        print("\nÃ–rnek:")
        print("python scripts/prepare_training_data.py --pdf training-data/collected/document.pdf --max-pages 50")


if __name__ == '__main__':
    main()
