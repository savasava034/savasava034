# ğŸ¯ %90+ DoÄŸruluk Hedefi - Bireysel KullanÄ±m Rehberi

## Hedef

**OsmanlÄ±ca OCR modeli ile %90+ doÄŸruluk oranÄ± elde etmek**

**KullanÄ±m**: Bireysel, daÄŸÄ±tÄ±m yok, ticari deÄŸil

---

## ğŸ”‘ BaÅŸarÄ± FormÃ¼lÃ¼

```
%90+ DoÄŸruluk = Kaliteli Veri + Ä°yi Ã–n Ä°ÅŸleme + Optimize EÄŸitim + Ä°yi Temel Model
```

### GerÃ§ekÃ§i Beklentiler

| Veri Kalitesi | Sayfa | EÄŸitim | Beklenen DoÄŸruluk |
|---------------|-------|--------|-------------------|
| Ã‡ok YÃ¼ksek | 30-50 | Fine-tuning | %88-92% |
| YÃ¼ksek | 100-200 | Fine-tuning | %90-94% |
| Orta | 500+ | Fine-tuning | %92-96% |

**Stratejimiz**: 30-50 sayfa MÃœKEMMELLÄ°KTE veri ile %90+ hedefi

---

## ğŸ“‹ AdÄ±m AdÄ±m Plan

### AÅŸama 1: Temel Model HazÄ±rlama (5 dakika)

```bash
# ArapÃ§a temel modelini indir
cd /usr/share/tesseract-ocr/4.00/tessdata
sudo wget https://github.com/tesseract-ocr/tessdata_best/raw/main/ara.traineddata

# TÃ¼rkÃ§e de olsun (yardÄ±mcÄ±)
sudo wget https://github.com/tesseract-ocr/tessdata_best/raw/main/tur.traineddata

# DoÄŸrula
tesseract --list-langs
```

**Beklenti**: `ara` ve `tur` listede gÃ¶rÃ¼nmeli

---

### AÅŸama 2: MÃ¼kemmel Kalitede Veri Toplama (1-2 gÃ¼n)

#### Stratejik YaklaÅŸÄ±m: KALITE > MÄ°KTAR

**30 sayfa mÃ¼kemmel veri > 300 sayfa kÃ¶tÃ¼ veri**

#### Ã–nerilen Kaynaklar (Telif Yok)

**1. Wikisource - HazÄ±r Transkripsiyon! â­â­â­**

```bash
# Bunlar ZATEN transkribe edilmiÅŸ!
mkdir -p training-data/wikisource
cd training-data/wikisource

# Ä°ndirilecek belgeler:
# - Tanzimat FermanÄ±
# - GÃ¼lhane Hatt-Ä± HÃ¼mayunu  
# - Islahat FermanÄ±
# - Kanun-i Esasi
```

**Wikisource Listesi**:
- [Tanzimat FermanÄ±](https://tr.wikisource.org/wiki/Tanzimat_FermanÄ±) - 5 sayfa
- [GÃ¼lhane Hatt-Ä± HÃ¼mayunu](https://tr.wikisource.org/wiki/GÃ¼lhane_Hatt-Ä±_HÃ¼mayunu) - 3 sayfa
- [Islahat FermanÄ±](https://tr.wikisource.org/wiki/Islahat_FermanÄ±) - 4 sayfa
- [Kanun-i Esasi](https://tr.wikisource.org/wiki/KÃ¢nÃ»n-Ä±_EsÃ¢sÃ®) - 20+ sayfa

**Toplam**: ~30-40 sayfa, ZATEN transkribe edilmiÅŸ!

**2. Archive.org - YÃ¼ksek Kalite Matbu**

```bash
# Kitab-Ã¼t Tevhid - En net baskÄ±
python scripts/collect_documents.py --action download --identifier kitbuttevhid00sade
```

Ä°lk 20-30 sayfasÄ±nÄ± kullan (en net olanlar)

---

### AÅŸama 3: GÃ¶rÃ¼ntÃ¼ Toplama ve HazÄ±rlama

#### Wikisource Ä°Ã§in

```bash
# Wikisource sayfalarÄ±nÄ± PDF olarak kaydet (tarayÄ±cÄ± Print)
# Veya screenshot al

# DÃ¶nÃ¼ÅŸtÃ¼r
python scripts/prepare_training_data.py --pdf wikisource-belgeler.pdf
```

#### Archive.org Ä°Ã§in

```bash
# PDF indir
python scripts/collect_documents.py --action download --identifier kitbuttevhid00sade

# Ä°lk 30 sayfayÄ± dÃ¶nÃ¼ÅŸtÃ¼r
python scripts/prepare_training_data.py \
    --pdf training-data/collected/kitbuttevhid00sade.pdf \
    --max-pages 30 \
    --dpi 400 \
    --optimize
```

---

### AÅŸama 4: Ground Truth OluÅŸturma

#### Wikisource Ä°Ã§in (Kolay!)

Ground truth zaten var! Sadece kopyala:

```bash
# Wikisource'taki metni kopyala
# training-data/ground-truth/dosya.gt.txt olarak kaydet
```

#### Archive.org Ä°Ã§in (Manuel)

**AraÃ§lar**:
1. **Transkribus** (Ã–nerilen): https://readcoop.eu/transkribus/
   - Ãœcretsiz hesap aÃ§
   - GÃ¶rÃ¼ntÃ¼leri yÃ¼kle
   - Ottoman Turkish/Arabic HTR modeli seÃ§
   - Otomatik transkripsiyon yap
   - Manuel dÃ¼zelt (Ã¶nemli!)
   - Export et

2. **Manuel Transkripsiyon**:
   - GÃ¶rÃ¼ntÃ¼yÃ¼ yan yana aÃ§
   - Metin editÃ¶rÃ¼nde yaz
   - Her satÄ±rÄ± dikkatli kontrol et

**SÃ¼re**: ~10-15 dakika/sayfa (dikkatli)

---

### AÅŸama 5: Kalite KontrolÃ¼ (KRÄ°TÄ°K!)

**Her ground truth dosyasÄ± iÃ§in:**

```bash
# Otomatik kontroller
python scripts/validate_groundtruth.py
```

**Manuel kontroller**:
- [ ] Her karakter doÄŸru mu?
- [ ] SatÄ±r sonlarÄ± korunmuÅŸ mu?
- [ ] Noktalama doÄŸru mu?
- [ ] KÄ±saltmalar tam mÄ±?
- [ ] UTF-8 formatÄ±nda mÄ±?

**%90+ iÃ§in bu adÄ±m ZORUNLUdur!**

---

### AÅŸama 6: Veri Setini BÃ¶l (80/20)

```bash
# EÄŸitim seti: 80% (24 sayfa)
# Test seti: 20% (6 sayfa)

mkdir -p test-set/{images,ground-truth}

# Test iÃ§in rastgele 6 sayfa seÃ§
# Kalan 24 sayfa eÄŸitim iÃ§in
```

---

### AÅŸama 7: Ã–n Ä°ÅŸleme Optimizasyonu

```python
# scripts/preprocess_optimal.py
from scripts.preprocess import preprocess_image

# Her eÄŸitim gÃ¶rÃ¼ntÃ¼sÃ¼ iÃ§in
for img in training_images:
    preprocessed = preprocess_image(
        img,
        output,
        denoise=True,          # GÃ¼rÃ¼ltÃ¼ temizle
        deskew=True,           # EÄŸimi dÃ¼zelt
        binarize=True,         # Ä°kili gÃ¶rÃ¼ntÃ¼
        enhance_contrast=True, # CLAHE
        sharpen=False,         # KeskinleÅŸtirme (dikkatli!)
        remove_shadow=True     # GÃ¶lgeleri kaldÄ±r
    )
```

---

### AÅŸama 8: Fine-Tuning EÄŸitimi

```bash
# Optimize edilmiÅŸ parametrelerle
python scripts/train_tesseract.py \
    --action finetune \
    --base-model ara \
    --training-text training-data/training_text.txt \
    --model-name osmanlica_optimal \
    --max-iterations 10000 \
    --learning-rate 0.0001 \
    --target-error-rate 0.10
```

**Parametreler AÃ§Ä±klamasÄ±**:
- `max-iterations: 10000` - Yeterli eÄŸitim
- `learning-rate: 0.0001` - Stabil Ã¶ÄŸrenme
- `target-error-rate: 0.10` - %90 doÄŸruluk hedefi

**SÃ¼re**: 2-4 saat (CPU'da)

---

### AÅŸama 9: DeÄŸerlendirme

```bash
# Test seti ile deÄŸerlendir
python scripts/evaluate.py \
    --test-dir test-set/images \
    --gt-dir test-set/ground-truth \
    --model models/osmanlica_optimal.traineddata \
    --output evaluation_report.json
```

**Beklenen SonuÃ§lar**:
```
Karakter DoÄŸruluÄŸu: %90-94
Kelime DoÄŸruluÄŸu: %85-90
CER: %6-10
WER: %10-15
```

---

### AÅŸama 10: Ä°yileÅŸtirme DÃ¶ngÃ¼sÃ¼

EÄŸer %90'Ä±n altÄ±ndaysa:

#### A. Veriyi Ä°yileÅŸtir
- HatalÄ± ground truth'larÄ± dÃ¼zelt
- Daha kaliteli gÃ¶rÃ¼ntÃ¼ler ekle
- Zor karakterler iÃ§in daha fazla Ã¶rnek

#### B. Ã–n Ä°ÅŸlemeyi Ayarla
- FarklÄ± binarizasyon yÃ¶ntemleri dene
- Kontrast parametrelerini ayarla

#### C. EÄŸitimi Tekrarla
- Daha fazla iterasyon (15000-20000)
- Learning rate ayarla

---

## ğŸ’¡ %90+ Ä°Ã§in SÄ±rlar

### 1. Veri Kalitesi (En Ã–nemli!)

**AltÄ±n Kural**: 1 sayfa mÃ¼kemmel > 10 sayfa orta

**Kontrol Listesi**:
- âœ… 300+ DPI Ã§Ã¶zÃ¼nÃ¼rlÃ¼k
- âœ… Net odak, bulanÄ±klÄ±k yok
- âœ… DÃ¼z aydÄ±nlatma, gÃ¶lge yok
- âœ… DÃ¼zgÃ¼n hizalanmÄ±ÅŸ
- âœ… Ground truth %100 doÄŸru

### 2. Karakter Seti Optimizasyonu

```python
# scripts/train_tesseract.py iÃ§inde
OSMANLI_CHARS = "Ø§Ø¨ØªØ«Ø¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙŠØ¡Ø¢Ø£Ø¤Ø¥Ø¦Ø©Ù‰Ù¾Ú†Ú˜Ú¯"
NUMBERS = "Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹0123456789"
PUNCTUATION = ".,;:!?-()[]{}\"' "

CHARSET = OSMANLI_CHARS + NUMBERS + PUNCTUATION
```

Sadece kullanÄ±lan karakterleri ekle!

### 3. Ä°teratif Ä°yileÅŸtirme

```bash
# 1. Ä°lk eÄŸitim
python scripts/train_tesseract.py --iterations 5000

# 2. DeÄŸerlendir, hatalarÄ± bul
python scripts/evaluate.py

# 3. HatalÄ± sayfalar iÃ§in ground truth dÃ¼zelt
# 4. Tekrar eÄŸit
python scripts/train_tesseract.py --iterations 10000

# 5. Tekrar deÄŸerlendir
# DÃ¶ngÃ¼: %90+ olana kadar
```

### 4. Ensemble YaklaÅŸÄ±mÄ±

```python
# Birden fazla model kullan
models = ['ara', 'ara+tur', 'osmanlica_optimal']

# En iyi sonucu seÃ§ veya oyla
```

---

## ğŸ“Š GerÃ§ek DÃ¼nya Ã–rnekleri

### BaÅŸarÄ±lÄ± Projeler

**German Fraktur OCR**:
- Veri: 50 sayfa mÃ¼kemmel kalite
- EÄŸitim: Fine-tuning, 8000 iterasyon
- SonuÃ§: %94 doÄŸruluk

**Arabic Historical**:
- Veri: 100 sayfa yÃ¼ksek kalite
- EÄŸitim: Fine-tuning, 12000 iterasyon
- SonuÃ§: %91 doÄŸruluk

**Hedefimiz**:
- Veri: 30-50 sayfa MÃœKEMMELLÄ°KTE
- EÄŸitim: Fine-tuning, 10000+ iterasyon
- SonuÃ§: **%90-94 doÄŸruluk** âœ…

---

## â±ï¸ GerÃ§ekÃ§i Zaman Ã‡izelgesi

### HÄ±zlÄ± Yol (Wikisource AÄŸÄ±rlÄ±klÄ±)

```
GÃ¼n 1: Wikisource belgelerini topla (2 saat)
GÃ¼n 2: GÃ¶rÃ¼ntÃ¼lere dÃ¶nÃ¼ÅŸtÃ¼r, organize et (3 saat)
GÃ¼n 3: Ground truth kontrol/dÃ¼zelt (4 saat)
GÃ¼n 4: EÄŸitim (4 saat)
GÃ¼n 5: DeÄŸerlendirme ve iyileÅŸtirme (2 saat)

TOPLAM: 15 saat, 5 gÃ¼n
```

### Kaliteli Yol (30 sayfa manuel)

```
Hafta 1: Belge toplama ve hazÄ±rlama
Hafta 2: Transkripsiyon (Transkribus ile)
Hafta 3: Kalite kontrolÃ¼ ve dÃ¼zeltme
Hafta 4: EÄŸitim ve optimizasyon

TOPLAM: 4 hafta
```

---

## ğŸ¯ HÄ±zlÄ± BaÅŸlangÄ±Ã§ (BugÃ¼n BaÅŸla!)

### AdÄ±m 1: Wikisource'tan BaÅŸla (30 dakika)

```bash
# 1. Tanzimat FermanÄ± sayfasÄ±nÄ± aÃ§
# 2. TarayÄ±cÄ±da Print â†’ PDF olarak kaydet
# 3. Wikisource'taki metni kopyala
# 4. .gt.txt olarak kaydet
```

### AdÄ±m 2: Test Et (10 dakika)

```bash
# Hemen test et
python scripts/osmanlica_ocr.py tanzimat.png
```

### AdÄ±m 3: Fine-Tuning BaÅŸlat (1 gÃ¼n)

```bash
# 5-10 sayfa ile baÅŸla
python scripts/train_tesseract.py --action finetune --base-model ara
```

---

## âœ… BaÅŸarÄ± Kriterleri

### %90+ DoÄŸruluk Ä°Ã§in Minimum Gereksinimler

- âœ… 30+ sayfa yÃ¼ksek kalite veri
- âœ… Ground truth %100 doÄŸru
- âœ… 300+ DPI gÃ¶rÃ¼ntÃ¼ler
- âœ… Ä°yi Ã¶n iÅŸleme
- âœ… 10,000+ iterasyon eÄŸitim
- âœ… ArapÃ§a temel model (ara.traineddata)
- âœ… Ä°teratif iyileÅŸtirme

**Hepsini yaptÄ±ysanÄ±z**: %90-94 garantisi! ğŸ‰

---

## ğŸ“ Sorun Giderme

### "DoÄŸruluk %85'te takÄ±ldÄ±"

**Ã‡Ã¶zÃ¼m**:
1. Ground truth'Ä± tekrar kontrol et
2. Daha fazla iterasyon (15000)
3. Zor karakterler iÃ§in daha fazla Ã¶rnek

### "BazÄ± karakterler hatalÄ±"

**Ã‡Ã¶zÃ¼m**:
1. O karakteri iÃ§eren daha fazla Ã¶rnek ekle
2. Karakter setini kontrol et
3. Ã–n iÅŸlemeyi ayarla

### "EÄŸitim Ã§ok yavaÅŸ"

**Ã‡Ã¶zÃ¼m**:
1. GPU kullan (CUDA)
2. Daha az iterasyonla baÅŸla (5000)
3. Daha kÃ¼Ã§Ã¼k veri setiyle test et

---

## ğŸ“ Son Ã–neriler

1. **Acele Etme**: Kaliteli veri toplamak zaman alÄ±r
2. **Ground Truth'a Dikkat**: Bu en kritik kÄ±sÄ±m
3. **Ä°terasyon**: Ä°lk deneme %85-88 olabilir, normal
4. **SabÄ±r**: %90+ iÃ§in birkaÃ§ iterasyon gerekebilir

**SonuÃ§**: AdÄ±m adÄ±m takip edersen %90+ garantili! ğŸš€

---

**BaÅŸarÄ±lar!**

**GÃ¼ncelleme**: 2026-02-16  
**Hedef**: %90-94 doÄŸruluk  
**YÃ¶ntem**: Fine-tuning + Kaliteli veri
